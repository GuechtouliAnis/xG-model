{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing an xg model based on the features extracted using MLlib\n",
    "# shot_statsbomb_xg is the target variable, the rest are the features\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import RandomForestRegressor, GBTRegressor, DecisionTreeRegressor, GeneralizedLinearRegression, IsotonicRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import pp_events as pp\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/21 21:06:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Training').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost model\n",
    "from xgboost import XGBRegressor\n",
    "# XGBoost, LightGBM, CatBoost\n",
    "#from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "#from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "events = spark.read.csv('Data/events.csv',header=True,inferSchema=True,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_t = ['id','match_id','player_id','player','position',\"shot_location_x\", \"shot_location_y\",\n",
    "             'distance_to_goal','shot_angle', 'shot_body_part','preferred_foot_shot', \n",
    "             'under_pressure','shot_statsbomb_xg','shot_outcome','goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#events_shot = pp.shot_data(events)\n",
    "events_shot = events.filter((events.type=='Shot') & (events.period < 5))\n",
    "events_shot = pp.split_location(events_shot)\n",
    "events_shot = pp.distance_to_goal(events_shot)\n",
    "events_shot = pp.get_shot_angle(events_shot)\n",
    "events_shot = pp.shot_preferred_foot(events_shot,events)\n",
    "events_shot = pp.goal(events_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_shot = events_shot.select(columns_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"under_pressure\",\"preferred_foot_shot\",'goal']\n",
    "ev = pp.bool_to_int(events_shot,cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = ev.na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"shot_location_x\", \"shot_location_y\", \"distance_to_goal\", \"shot_angle\", 'under_pressure', 'preferred_foot_shot']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "data = assembler.transform(ev).select(\"features\", \"goal\", \"shot_statsbomb_xg\")\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models with label set to 'goal'\n",
    "rf = RandomForestRegressor(labelCol=\"goal\", featuresCol=\"features\")\n",
    "gbt = GBTRegressor(labelCol=\"goal\", featuresCol=\"features\")\n",
    "dt = DecisionTreeRegressor(labelCol=\"goal\", featuresCol=\"features\")\n",
    "glr = GeneralizedLinearRegression(labelCol=\"goal\", featuresCol=\"features\")\n",
    "ir = IsotonicRegression(labelCol=\"goal\", featuresCol=\"features\")\n",
    "\n",
    "# Create a list of models and their names\n",
    "models = [rf, gbt, dt, glr, ir]\n",
    "model_names = [\"Random Forest\", \"Gradient Boosted Trees\", \"Decision Tree\", \"Generalized Linear Regression\",\n",
    "               \"Isotonic Regression\"]\n",
    "\n",
    "# Create pipelines for each model\n",
    "model_pipelines = [Pipeline(stages=[model]) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/21 21:34:45 WARN Instrumentation: [7634b5e6] regParam is zero, which might cause numerical instability and overfitting.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Train each model\n",
    "fitted_models = [pipeline.fit(train_data) for pipeline in model_pipelines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 0.12211494856400057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Trees RMSE: 0.11530225458657559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree RMSE: 0.1180496047719669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Linear Regression RMSE: 0.13063893956537284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotonic Regression RMSE: 0.14656223085733164\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on `shot_statsbomb_xg`\n",
    "evaluator = RegressionEvaluator(labelCol=\"shot_statsbomb_xg\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = []\n",
    "\n",
    "for i, fitted_model in enumerate(fitted_models):\n",
    "    # Generate predictions\n",
    "    predictions = fitted_model.transform(test_data)\n",
    "    \n",
    "    # Map predicted probabilities to `shot_statsbomb_xg` range if applicable\n",
    "    predictions = predictions.withColumn(\"prediction\", col(\"prediction\") * col(\"shot_statsbomb_xg\"))  # Adjust based on logic\n",
    "    \n",
    "    # Evaluate RMSE\n",
    "    model_rmse = evaluator.evaluate(predictions)\n",
    "    rmse.append(model_rmse)\n",
    "    print(model_names[i] + \" RMSE: \" + str(model_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/21 21:44:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/21 21:44:32 WARN ResourceUtils: The configuration of cores (exec = 12 task = 1, runnable tasks = 12) will result in wasted resources due to resource gpu limiting the number of runnable tasks per executor to: 1. Please adjust your configuration.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"GPU Check\") \\\n",
    "    .config(\"spark.executor.resource.gpu.amount\", \"1\")\\\n",
    "    .config(\"spark.task.resource.gpu.amount\", \"1\") \\\n",
    "    .config(\"spark.executorEnv.LD_LIBRARY_PATH\", \"/usr/local/cuda/lib64\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time spent to run : 1m 54s for [\"shot_location_x\", \"shot_location_y\", \"distance_to_goal\", \"shot_angle\"] 0.09\n",
    "# Time spent to run : 1m 50s for [\"distance_to_goal\", \"shot_angle\"]                                       0.10\n",
    "\n",
    "# Consider using Classification instead of Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
