{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing an xg model based on the features extracted using MLlib\n",
    "# shot_statsbomb_xg is the target variable, the rest are the features\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor, DecisionTreeRegressor, GeneralizedLinearRegression, IsotonicRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "import pp_events as pp\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/21 16:19:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/21 16:19:31 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Training').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost model\n",
    "from xgboost import XGBRegressor\n",
    "# XGBoost, LightGBM, CatBoost\n",
    "#from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "#from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = spark.read.csv('Data/events.csv',header=True,inferSchema=True,sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_shot = events.filter(events.type=='Shot')\n",
    "\n",
    "events_shot = pp.split_location(events_shot)\n",
    "events_shot = pp.distance_to_goal(events_shot)\n",
    "events_shot = pp.get_shot_angle(events_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"shot_location_x\", \"shot_location_y\", \"distance_to_goal\", \"shot_angle\"]\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "data = assembler.transform(events_shot).select(\"features\", \"shot_statsbomb_xg\")\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all models\n",
    "lr = LinearRegression(labelCol=\"shot_statsbomb_xg\", featuresCol=\"features\")\n",
    "rf = RandomForestRegressor(labelCol=\"shot_statsbomb_xg\", featuresCol=\"features\")\n",
    "gbt = GBTRegressor(labelCol=\"shot_statsbomb_xg\", featuresCol=\"features\")\n",
    "dt = DecisionTreeRegressor(labelCol=\"shot_statsbomb_xg\", featuresCol=\"features\")\n",
    "glr = GeneralizedLinearRegression(labelCol=\"shot_statsbomb_xg\", featuresCol=\"features\")\n",
    "ir = IsotonicRegression(labelCol=\"shot_statsbomb_xg\", featuresCol=\"features\")\n",
    "\n",
    "# Create a list of models\n",
    "models = [lr, rf, gbt, dt, glr, ir]\n",
    "\n",
    "# Create a list of model names\n",
    "model_names = [\"Linear Regression\", \"Random Forest\", \"Gradient Boosted Trees\", \"Decision Tree\", \"Generalized Linear Regression\", \"Isotonic Regression\"]\n",
    "\n",
    "# Create a list of model pipelines\n",
    "model_pipelines = [Pipeline(stages=[model]) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit each model pipeline\n",
    "fitted_models = [pipeline.fit(train_data) for pipeline in model_pipelines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model\n",
    "evaluator = RegressionEvaluator(labelCol=\"shot_statsbomb_xg\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "predictions = [fitted_model.transform(test_data) for fitted_model in fitted_models]\n",
    "rmse = [evaluator.evaluate(prediction) for prediction in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the RMSE of each model\n",
    "for i in range(len(models)):\n",
    "    print(model_names[i] + \" RMSE: \" + str(rmse[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time spent to run : 1m 54s for [\"shot_location_x\", \"shot_location_y\", \"distance_to_goal\", \"shot_angle\"] 0.09\n",
    "# Time spent to run : 1m 50s for [\"distance_to_goal\", \"shot_angle\"]                                       0.10\n",
    "\n",
    "# Consider using Classification instead of Regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
