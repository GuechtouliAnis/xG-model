{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import xgboost as xgb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/27 01:32:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"xgb\").getOrCreate()\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_shot = spark.read.csv('Datas/events_shot.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['other_pp','from_fk','from_ti','from_corner','from_counter','from_gk','from_keeper','from_ko',\n",
    "            'header','corner_type','fk_type','pk_type',\n",
    "            'half_volley_technique','volley_technique','lob_technique','overhead_technique','backheel_technique','diving_h_technique',\n",
    "            'distance_to_goal', 'shot_angle', 'preferred_foot_shot', 'under_pressure',\n",
    "            'shot_aerial_won','shot_first_time','shot_one_on_one','shot_open_goal','shot_follows_dribble','players_inside_area']\n",
    "target = ['goal'] # sb_prediction, shot_statsbomb_xg, goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = events_shot.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7932897669112459\n",
      "0.9012741438078234\n",
      "0.0987258561921766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, mean_squared_error\n",
    "\n",
    "target = 'goal'\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=40)\n",
    "\n",
    "# Create DMatrix for training data (only use training data)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "# Create DMatrix for test data (only use test data)\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # Binary classification objective\n",
    "    'eval_metric': 'auc',            # Evaluation metric (AUC for binary classification)\n",
    "    'learning_rate': 0.05,           # Slightly lower learning rate for finer updates\n",
    "    'max_depth': 10,                 # Slightly deeper trees for capturing more complex patterns\n",
    "    'subsample': 0.85,               # Slightly higher subsample for better data utilization\n",
    "    'colsample_bytree': 0.9,         # Increase feature sampling for more diversity in trees\n",
    "    'min_child_weight': 2,           # Slightly lower value to allow more splits if needed\n",
    "    'gamma': 0.3,                    # Increase gamma to make the model more conservative\n",
    "    'alpha': 0.2,                    # Increased L1 regularization to reduce overfitting\n",
    "    'lambda': 1.5,                   # Increase L2 regularization to further prevent overfitting\n",
    "    'scale_pos_weight': 1,           # Adjust this if you have class imbalance (optional)\n",
    "    'nthread': 4,                    # Use multiple threads to speed up training (if applicable)\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "num_round = 500\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Calculate ROC-AUC score on test data\n",
    "print(roc_auc_score(y_test, y_pred))\n",
    "\n",
    "# Accuracy\n",
    "y_pred = [1 if x >= 0.5 else 0 for x in y_pred]\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# rmse\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
