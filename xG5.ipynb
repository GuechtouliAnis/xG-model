{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import round,col, when, udf, format_number, abs, avg\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pp_events as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/26 02:02:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"xG5\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_shot = spark.read.csv('Datas/events_shot.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n",
      "Spatial data calculated\n",
      "Preferred foot calculated\n",
      "Goal column created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of players inside the area calculated\n",
      "Dummies created\n",
      "Boolean data converted to integer\n"
     ]
    }
   ],
   "source": [
    "# events_shot = pp.preprocessing(events,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'player_id',\n",
       " 'shot_location_x',\n",
       " 'shot_location_y',\n",
       " 'distance_to_goal',\n",
       " 'shot_angle',\n",
       " 'preferred_foot_shot',\n",
       " 'other_pp',\n",
       " 'from_fk',\n",
       " 'from_ti',\n",
       " 'from_corner',\n",
       " 'from_counter',\n",
       " 'from_gk',\n",
       " 'from_keeper',\n",
       " 'from_ko',\n",
       " 'header',\n",
       " 'corner_type',\n",
       " 'fk_type',\n",
       " 'pk_type',\n",
       " 'half_volley_technique',\n",
       " 'volley_technique',\n",
       " 'lob_technique',\n",
       " 'overhead_technique',\n",
       " 'backheel_technique',\n",
       " 'diving_h_technique',\n",
       " 'under_pressure',\n",
       " 'shot_aerial_won',\n",
       " 'shot_first_time',\n",
       " 'shot_one_on_one',\n",
       " 'shot_open_goal',\n",
       " 'shot_follows_dribble',\n",
       " 'players_inside_area',\n",
       " 'shot_statsbomb_xg',\n",
       " 'shot_outcome',\n",
       " 'goal',\n",
       " 'sb_prediction']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events_shot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['other_pp','from_fk','from_ti','from_corner','from_counter','from_gk','from_keeper','from_ko',\n",
    "            'header','corner_type','fk_type','pk_type',\n",
    "            'half_volley_technique','volley_technique','lob_technique','overhead_technique','backheel_technique','diving_h_technique',\n",
    "            'distance_to_goal', 'shot_angle', 'preferred_foot_shot', 'under_pressure',\n",
    "            'shot_aerial_won','shot_first_time','shot_one_on_one','shot_open_goal','shot_follows_dribble','players_inside_area']\n",
    "target = ['goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(features)\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Define the assembler\n",
    "feature_assembler = VectorAssembler(inputCols=features, outputCol=\"features_vector\")\n",
    "\n",
    "# Transform the dataset\n",
    "assembled_data = feature_assembler.transform(events_shot)\n",
    "train_data, test_data = assembled_data.randomSplit([0.6, 0.4], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/26 02:02:43 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.8064436514412713\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Define the logistic regression model\n",
    "log_reg = LogisticRegression(featuresCol=\"features_vector\", labelCol=\"goal\", maxIter=10)\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[log_reg])\n",
    "# Still rerunning all, fix that\n",
    "xg_model = pipeline.fit(train_data)\n",
    "# Make predictions\n",
    "predictions = xg_model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"goal\", rawPredictionCol=\"rawPrediction\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC-AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.7894294261237248\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Define the Random Forest classifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features_vector\", labelCol=\"goal\", numTrees=100)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[rf])\n",
    "\n",
    "# Fit the model\n",
    "xg_model = pipeline.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = xg_model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"goal\", rawPredictionCol=\"rawPrediction\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC-AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1263:==================>                                     (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.8016156467325752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Define the Multilayer Perceptron classifier\n",
    "layers = [input_size, 128, 64, 32, 16, output_size]\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(featuresCol=\"features_vector\", labelCol=\"goal\", maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[mlp])\n",
    "\n",
    "# Fit the model\n",
    "xg_model = pipeline.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = xg_model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"goal\", rawPredictionCol=\"rawPrediction\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC-AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.8092147820750702\n"
     ]
    }
   ],
   "source": [
    "#### BEST MODEL SO FAR ####\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "# Define the Gradient-Boosted Tree classifier\n",
    "gbt = GBTClassifier(featuresCol=\"features_vector\", labelCol=\"goal\", maxIter=50)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "\n",
    "# Fit the model\n",
    "xg_model = pipeline.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = xg_model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"goal\", rawPredictionCol=\"rawPrediction\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC-AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/26 02:02:49 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 39:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-------------+--------------+\n",
      "|shot_statsbomb_xg|goal_probability|difference   |difference_abs|\n",
      "+-----------------+----------------+-------------+--------------+\n",
      "|0.056764796      |0.0344632589    |0.0223015371 |0.0223015371  |\n",
      "|0.10166888       |0.1859838849    |-0.0843150049|0.0843150049  |\n",
      "|0.018964255      |0.0141866550    |0.0047776000 |0.0047776000  |\n",
      "|0.026109         |0.0339147733    |-0.0078057733|0.0078057733  |\n",
      "|0.064399794      |0.0991593249    |-0.0347595309|0.0347595309  |\n",
      "|0.03170719       |0.0282146087    |0.0034925813 |0.0034925813  |\n",
      "|0.0063226367     |0.0022686959    |0.0040539408 |0.0040539408  |\n",
      "|0.033228997      |0.0562202854    |-0.0229912884|0.0229912884  |\n",
      "|0.052520916      |0.0211469453    |0.0313739707 |0.0313739707  |\n",
      "|0.042308386      |0.0558115216    |-0.0135031356|0.0135031356  |\n",
      "|0.13170753       |0.3056605533    |-0.1739530233|0.1739530233  |\n",
      "|0.14392917       |0.1767992292    |-0.0328700592|0.0328700592  |\n",
      "|0.07543106       |0.0559069323    |0.0195241277 |0.0195241277  |\n",
      "|0.073996074      |0.0655086600    |0.0084874140 |0.0084874140  |\n",
      "|0.0447311        |0.1222290552    |-0.0774979552|0.0774979552  |\n",
      "|0.050162695      |0.0857024567    |-0.0355397617|0.0355397617  |\n",
      "|0.7835           |0.7141124878    |0.0693875122 |0.0693875122  |\n",
      "|0.02591278       |0.0130175824    |0.0128951976 |0.0128951976  |\n",
      "|0.057676427      |0.0495549326    |0.0081214944 |0.0081214944  |\n",
      "|0.0776978        |0.0806932289    |-0.0029954289|0.0029954289  |\n",
      "|0.10890295       |0.1225381636    |-0.0136352136|0.0136352136  |\n",
      "|0.0968482        |0.1102849837    |-0.0134367837|0.0134367837  |\n",
      "|0.03492738       |0.0366453879    |-0.0017180079|0.0017180079  |\n",
      "|0.15445817       |0.1819772853    |-0.0275191153|0.0275191153  |\n",
      "|0.05416238       |0.0250689682    |0.0290934118 |0.0290934118  |\n",
      "|0.07232883       |0.0817373647    |-0.0094085347|0.0094085347  |\n",
      "|0.087863006      |0.0895430668    |-0.0016800608|0.0016800608  |\n",
      "|0.121686585      |0.1365194454    |-0.0148328604|0.0148328604  |\n",
      "|0.0638635        |0.0600052319    |0.0038582681 |0.0038582681  |\n",
      "|0.25546068       |0.2008177199    |0.0546429601 |0.0546429601  |\n",
      "|0.0956086        |0.1596150471    |-0.0640064471|0.0640064471  |\n",
      "|0.25332773       |0.2676994970    |-0.0143717670|0.0143717670  |\n",
      "|0.31239024       |0.2852910799    |0.0270991601 |0.0270991601  |\n",
      "|0.1517978        |0.2074492517    |-0.0556514517|0.0556514517  |\n",
      "|0.030001678      |0.0343509544    |-0.0043492764|0.0043492764  |\n",
      "|0.024012579      |0.0085495695    |0.0154630095 |0.0154630095  |\n",
      "|0.04799039       |0.0449944508    |0.0029959392 |0.0029959392  |\n",
      "|0.038757622      |0.0620919453    |-0.0233343233|0.0233343233  |\n",
      "|0.016418302      |0.0071590152    |0.0092592868 |0.0092592868  |\n",
      "|0.2918426        |0.1588580136    |0.1329845864 |0.1329845864  |\n",
      "|0.10885255       |0.1097545354    |-0.0009019854|0.0009019854  |\n",
      "|0.032042325      |0.0814293228    |-0.0493869978|0.0493869978  |\n",
      "|0.20368662       |0.1569054390    |0.0467811810 |0.0467811810  |\n",
      "|0.054131273      |0.0535848411    |0.0005464319 |0.0005464319  |\n",
      "|0.061207097      |0.0372287723    |0.0239783247 |0.0239783247  |\n",
      "|0.08138597       |0.1131822173    |-0.0317962473|0.0317962473  |\n",
      "|0.08405946       |0.0175977831    |0.0664616769 |0.0664616769  |\n",
      "|0.3084018        |0.1539177091    |0.1544840909 |0.1544840909  |\n",
      "|0.03956943       |0.0416854010    |-0.0021159710|0.0021159710  |\n",
      "|0.2272298        |0.2786765663    |-0.0514467663|0.0514467663  |\n",
      "+-----------------+----------------+-------------+--------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Define a function to extract the probability of the goal (class 1)\n",
    "def extract_goal_probability(probability):\n",
    "    return float(probability[1])\n",
    "\n",
    "# Register the function as a UDF\n",
    "extract_goal_probability_udf = udf(extract_goal_probability, DoubleType())\n",
    "\n",
    "# Create a new column with the goal probability\n",
    "predictions_with_goal_prob = predictions.withColumn(\"goal_probability\", extract_goal_probability_udf(col(\"probability\")))\n",
    "\n",
    "# Format the goal_probability to remove scientific notation\n",
    "predictions_with_goal_prob = predictions_with_goal_prob.withColumn(\"goal_probability\", format_number(col(\"goal_probability\"), 10))\n",
    "\n",
    "# Add a new column showing the difference between shot_statsbomb_xg and goal_probability\n",
    "predictions_with_goal_prob = predictions_with_goal_prob.\\\n",
    "    withColumn(\"difference\", format_number(col(\"shot_statsbomb_xg\") - col(\"goal_probability\"),10))\n",
    "\n",
    "predictions_with_goal_prob = predictions_with_goal_prob.\\\n",
    "    withColumn(\"difference_abs\", format_number(abs(col('difference')),10))\n",
    "\n",
    "# Show the results\n",
    "predictions_with_goal_prob.select(\"shot_statsbomb_xg\", \"goal_probability\", \"difference\",'difference_abs').show(50,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference: -0.009062188503877534\n",
      "Abs average difference: 0.03445555759480951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# average of the difference\n",
    "avg_diff = predictions_with_goal_prob.select(avg(col(\"difference\"))).collect()[0][0]\n",
    "abs_avg_diff = predictions_with_goal_prob.select(avg(col(\"difference_abs\"))).collect()[0][0]\n",
    "\n",
    "print(f\"Average difference: {avg_diff}\")\n",
    "print(f\"Abs average difference: {abs_avg_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 90.41%\n",
      "StatsBomb xG Accuracy: 90.61%\n"
     ]
    }
   ],
   "source": [
    "# round the goal_probability to 0 or 1, same for the shot_statsbomb_xg and compare with goal to check the accuracy of the model\n",
    "# vs the accuracy of the shot_statsbomb_xg model\n",
    "predictions_with_goal_prob = predictions_with_goal_prob.withColumn(\"goal_probability_rounded\", round(col(\"goal_probability\")))\\\n",
    "    .withColumn(\"shot_statsbomb_xg_rounded\", round(col(\"shot_statsbomb_xg\")))\n",
    "\n",
    "# Check if the rounded probability matches the actual goal for your model\n",
    "predictions_with_accuracy = predictions_with_goal_prob.withColumn(\n",
    "    \"model_correct\", when(col(\"goal\") == col(\"goal_probability_rounded\"), 1).otherwise(0))\\\n",
    "    .withColumn(\"statsbomb_correct\", when(col(\"goal\") == col(\"shot_statsbomb_xg_rounded\"), 1).otherwise(0))\n",
    "# Calculate accuracy\n",
    "accuracy_model = predictions_with_accuracy.selectExpr(\"avg(model_correct) as model_accuracy\").first()[\"model_accuracy\"]\n",
    "accuracy_statsbomb = predictions_with_accuracy.selectExpr(\"avg(statsbomb_correct) as statsbomb_accuracy\").first()[\"statsbomb_accuracy\"]\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy_model * 100:.2f}%\")\n",
    "print(f\"StatsBomb xG Accuracy: {accuracy_statsbomb * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models matching percentage: 98.06%\n"
     ]
    }
   ],
   "source": [
    "# Testing matching of models, is out model as good as SB_xg?\n",
    "predictions_with_accuracy = predictions_with_goal_prob.withColumn(\n",
    "    \"model_to_sbxg\", when(col(\"goal_probability_rounded\") == col(\"shot_statsbomb_xg_rounded\"), 1).otherwise(0))\n",
    "\n",
    "xg_accuracy_model = predictions_with_accuracy.selectExpr(\"avg(model_to_sbxg) as model_accuracy\").first()[\"model_accuracy\"]\n",
    "\n",
    "print(f\"Models matching percentage: {xg_accuracy_model * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show each feature with its coefficient\n",
    "coefficients = xg_model.stages[-1].coefficients\n",
    "features_coefficients = list(zip(features, coefficients))\n",
    "\n",
    "for feature, coefficient in features_coefficients:\n",
    "    print(f\"{feature}: {coefficient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = xg_model.transform(train_data)\n",
    "test_predictions = xg_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 91.08%\n",
      "Test accuracy: 90.41%\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy for each model\n",
    "train_accuracy = train_predictions.filter(train_predictions.goal == train_predictions.prediction).count() / train_predictions.count()\n",
    "\n",
    "test_accuracy = test_predictions.filter(test_predictions.goal == test_predictions.prediction).count() / test_predictions.count()\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
