{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import round,col, when, udf, format_number, abs, avg\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.types import DoubleType\n",
    "import pp_events as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/26 02:50:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"xG5\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_shot = spark.read.csv('Datas/events_shot.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# events_shot = pp.preprocessing(events,spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['other_pp','from_fk','from_ti','from_corner','from_counter','from_gk','from_keeper','from_ko',\n",
    "            'header','corner_type','fk_type','pk_type',\n",
    "            'half_volley_technique','volley_technique','lob_technique','overhead_technique','backheel_technique','diving_h_technique',\n",
    "            'distance_to_goal', 'shot_angle', 'preferred_foot_shot', 'under_pressure',\n",
    "            'shot_aerial_won','shot_first_time','shot_one_on_one','shot_open_goal','shot_follows_dribble','players_inside_area']\n",
    "target = ['goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(features)\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Define the assembler\n",
    "feature_assembler = VectorAssembler(inputCols=features, outputCol=\"features_vector\")\n",
    "\n",
    "# Transform the dataset\n",
    "assembled_data = feature_assembler.transform(events_shot)\n",
    "train_data, test_data = assembled_data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/26 02:50:37 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.8064468687686451\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Define the logistic regression model\n",
    "log_reg = LogisticRegression(featuresCol=\"features_vector\", labelCol=\"goal\", maxIter=10)\n",
    "xg_model = log_reg.fit(train_data)\n",
    "# Make predictions\n",
    "predictions = xg_model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"goal\", rawPredictionCol=\"rawPrediction\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC-AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/26 02:53:47 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.7813334077343806\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features_vector\", labelCol=\"goal\", numTrees=100)\n",
    "xg_model = rf.fit(train_data)\n",
    "predictions = xg_model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"goal\", rawPredictionCol=\"rawPrediction\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC-AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.8057324785364578\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "# Define the Multilayer Perceptron classifier\n",
    "layers = [input_size, 128, 64, 32, 16, output_size]\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(featuresCol=\"features_vector\", labelCol=\"goal\", maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "xg_model = mlp.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = xg_model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"goal\", rawPredictionCol=\"rawPrediction\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC-AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.8135336689098985\n"
     ]
    }
   ],
   "source": [
    "#### BEST MODEL SO FAR ####\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "# Define the Gradient-Boosted Tree classifier\n",
    "gbt = GBTClassifier(featuresCol=\"features_vector\", labelCol=\"goal\", maxIter=50)\n",
    "xg_model = gbt.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = xg_model.transform(test_data)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"goal\", rawPredictionCol=\"rawPrediction\")\n",
    "roc_auc = evaluator.evaluate(predictions)\n",
    "print(f\"ROC-AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+-------------+--------------+\n",
      "|shot_statsbomb_xg|goal_probability|difference   |difference_abs|\n",
      "+-----------------+----------------+-------------+--------------+\n",
      "|0.10166888       |0.1462401185    |-0.0445712385|0.0445712385  |\n",
      "|0.026109         |0.0452431335    |-0.0191341335|0.0191341335  |\n",
      "|0.064399794      |0.1391158998    |-0.0747161058|0.0747161058  |\n",
      "|0.033228997      |0.0527047067    |-0.0194757097|0.0194757097  |\n",
      "|0.14392917       |0.2454218257    |-0.1014926557|0.1014926557  |\n",
      "|0.073996074      |0.0803258191    |-0.0063297451|0.0063297451  |\n",
      "|0.7835           |0.8066456056    |-0.0231456056|0.0231456056  |\n",
      "|0.10890295       |0.1079249595    |0.0009779905 |0.0009779905  |\n",
      "|0.05416238       |0.0562240482    |-0.0020616682|0.0020616682  |\n",
      "|0.07232883       |0.0699231436    |0.0024056864 |0.0024056864  |\n",
      "|0.087863006      |0.0559036661    |0.0319593399 |0.0319593399  |\n",
      "|0.121686585      |0.1459664686    |-0.0242798836|0.0242798836  |\n",
      "|0.0638635        |0.0569627473    |0.0069007527 |0.0069007527  |\n",
      "|0.25546068       |0.2325196660    |0.0229410140 |0.0229410140  |\n",
      "|0.31239024       |0.3255463121    |-0.0131560721|0.0131560721  |\n",
      "|0.030001678      |0.0382191912    |-0.0082175132|0.0082175132  |\n",
      "|0.016418302      |0.0257648737    |-0.0093465717|0.0093465717  |\n",
      "|0.061207097      |0.0362173230    |0.0249897740 |0.0249897740  |\n",
      "|0.3084018        |0.2787890416    |0.0296127584 |0.0296127584  |\n",
      "|0.2272298        |0.2513711227    |-0.0241413227|0.0241413227  |\n",
      "|0.07770824       |0.1177321124    |-0.0400238724|0.0400238724  |\n",
      "|0.021341342      |0.0288768952    |-0.0075355532|0.0075355532  |\n",
      "|0.23812428       |0.3883303344    |-0.1502060544|0.1502060544  |\n",
      "|0.021880424      |0.0404775629    |-0.0185971389|0.0185971389  |\n",
      "|0.5082335        |0.3883303344    |0.1199031656 |0.1199031656  |\n",
      "|0.06866029       |0.0804764926    |-0.0118162026|0.0118162026  |\n",
      "|0.029000064      |0.0284809662    |0.0005190978 |0.0005190978  |\n",
      "|0.06347098       |0.0787139426    |-0.0152429626|0.0152429626  |\n",
      "|0.054039445      |0.0410529314    |0.0129865136 |0.0129865136  |\n",
      "|0.090416625      |0.0799250993    |0.0104915257 |0.0104915257  |\n",
      "|0.13947101       |0.1120481524    |0.0274228576 |0.0274228576  |\n",
      "|0.06449234       |0.0839747017    |-0.0194823617|0.0194823617  |\n",
      "|0.10414206       |0.0892634095    |0.0148786505 |0.0148786505  |\n",
      "|0.04430043       |0.0355708987    |0.0087295313 |0.0087295313  |\n",
      "|0.051667962      |0.1090790033    |-0.0574110413|0.0574110413  |\n",
      "|0.0886813        |0.0841226890    |0.0045586110 |0.0045586110  |\n",
      "|0.0508354        |0.0473023823    |0.0035330177 |0.0035330177  |\n",
      "|0.40448925       |0.3255463121    |0.0789429379 |0.0789429379  |\n",
      "|0.04622492       |0.0438409232    |0.0023839968 |0.0023839968  |\n",
      "|0.052129567      |0.0622886922    |-0.0101591252|0.0101591252  |\n",
      "|0.052356403      |0.0773535410    |-0.0249971380|0.0249971380  |\n",
      "|0.21282902       |0.1306497989    |0.0821792211 |0.0821792211  |\n",
      "|0.008616232      |0.0294698012    |-0.0208535692|0.0208535692  |\n",
      "|0.22353202       |0.1125680679    |0.1109639521 |0.1109639521  |\n",
      "|0.060671132      |0.0620157473    |-0.0013446153|0.0013446153  |\n",
      "|0.0066638533     |0.0273588925    |-0.0206950392|0.0206950392  |\n",
      "|0.09427214       |0.0623646682    |0.0319074718 |0.0319074718  |\n",
      "|0.63186514       |0.8078965120    |-0.1760313720|0.1760313720  |\n",
      "|0.18044521       |0.2322886703    |-0.0518434603|0.0518434603  |\n",
      "|0.014336902      |0.0346073777    |-0.0202704757|0.0202704757  |\n",
      "+-----------------+----------------+-------------+--------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a function to extract the probability of the goal (class 1)\n",
    "def extract_goal_probability(probability):\n",
    "    return float(probability[1])\n",
    "\n",
    "# Register the function as a UDF\n",
    "extract_goal_probability_udf = udf(extract_goal_probability, DoubleType())\n",
    "\n",
    "# Create a new column with the goal probability\n",
    "predictions_with_goal_prob = predictions.withColumn(\"goal_probability\", extract_goal_probability_udf(col(\"probability\")))\n",
    "\n",
    "# Format the goal_probability to remove scientific notation\n",
    "predictions_with_goal_prob = predictions_with_goal_prob.withColumn(\"goal_probability\", format_number(col(\"goal_probability\"), 10))\n",
    "\n",
    "# Add a new column showing the difference between shot_statsbomb_xg and goal_probability\n",
    "predictions_with_goal_prob = predictions_with_goal_prob.\\\n",
    "    withColumn(\"difference\", format_number(col(\"shot_statsbomb_xg\") - col(\"goal_probability\"),10))\n",
    "\n",
    "predictions_with_goal_prob = predictions_with_goal_prob.\\\n",
    "    withColumn(\"difference_abs\", format_number(abs(col('difference')),10))\n",
    "\n",
    "# Show the results\n",
    "predictions_with_goal_prob.select(\"shot_statsbomb_xg\", \"goal_probability\", \"difference\",'difference_abs').show(50,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difference: -0.007900773161505548\n",
      "Abs average difference: 0.03216420972981491\n"
     ]
    }
   ],
   "source": [
    "# average of the difference\n",
    "avg_diff = predictions_with_goal_prob.select(avg(col(\"difference\"))).collect()[0][0]\n",
    "abs_avg_diff = predictions_with_goal_prob.select(avg(col(\"difference_abs\"))).collect()[0][0]\n",
    "\n",
    "print(f\"Average difference: {avg_diff}\")\n",
    "print(f\"Abs average difference: {abs_avg_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 90.22%\n",
      "StatsBomb xG Accuracy: 90.32%\n"
     ]
    }
   ],
   "source": [
    "# round the goal_probability to 0 or 1, same for the shot_statsbomb_xg and compare with goal to check the accuracy of the model\n",
    "# vs the accuracy of the shot_statsbomb_xg model\n",
    "predictions_with_goal_prob = predictions_with_goal_prob.withColumn(\"goal_probability_rounded\", round(col(\"goal_probability\")))\\\n",
    "    .withColumn(\"shot_statsbomb_xg_rounded\", round(col(\"shot_statsbomb_xg\")))\n",
    "\n",
    "# Check if the rounded probability matches the actual goal for your model\n",
    "predictions_with_accuracy = predictions_with_goal_prob.withColumn(\n",
    "    \"model_correct\", when(col(\"goal\") == col(\"goal_probability_rounded\"), 1).otherwise(0))\\\n",
    "    .withColumn(\"statsbomb_correct\", when(col(\"goal\") == col(\"shot_statsbomb_xg_rounded\"), 1).otherwise(0))\n",
    "# Calculate accuracy\n",
    "accuracy_model = predictions_with_accuracy.selectExpr(\"avg(model_correct) as model_accuracy\").first()[\"model_accuracy\"]\n",
    "accuracy_statsbomb = predictions_with_accuracy.selectExpr(\"avg(statsbomb_correct) as statsbomb_accuracy\").first()[\"statsbomb_accuracy\"]\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy_model * 100:.2f}%\")\n",
    "print(f\"StatsBomb xG Accuracy: {accuracy_statsbomb * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models matching percentage: 98.57%\n"
     ]
    }
   ],
   "source": [
    "# Testing matching of models, is out model as good as SB_xg?\n",
    "predictions_with_accuracy = predictions_with_goal_prob.withColumn(\n",
    "    \"model_to_sbxg\", when(col(\"goal_probability_rounded\") == col(\"shot_statsbomb_xg_rounded\"), 1).otherwise(0))\n",
    "\n",
    "xg_accuracy_model = predictions_with_accuracy.selectExpr(\"avg(model_to_sbxg) as model_accuracy\").first()[\"model_accuracy\"]\n",
    "\n",
    "print(f\"Models matching percentage: {xg_accuracy_model * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show each feature with its coefficient\n",
    "coefficients = xg_model.stages[-1].coefficients\n",
    "features_coefficients = list(zip(features, coefficients))\n",
    "\n",
    "for feature, coefficient in features_coefficients:\n",
    "    print(f\"{feature}: {coefficient}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 91.05%\n",
      "Test accuracy: 90.22%\n"
     ]
    }
   ],
   "source": [
    "train_predictions = xg_model.transform(train_data)\n",
    "test_predictions = xg_model.transform(test_data)\n",
    "# calculate accuracy for each model\n",
    "train_accuracy = train_predictions.filter(train_predictions.goal == train_predictions.prediction).count() / train_predictions.count()\n",
    "test_accuracy = test_predictions.filter(test_predictions.goal == test_predictions.prediction).count() / test_predictions.count()\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
